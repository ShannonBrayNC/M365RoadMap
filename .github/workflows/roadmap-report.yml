name: Roadmap Report

on:
  workflow_dispatch:
    inputs:
      TITLE:
        description: Base name for output files (no extension)
        required: false
        default: roadmap_report
      PUBLIC_IDS:
        description: Comma-separated Roadmap IDs to force include
        required: false
        default: ""
      MONTHS:
        description: Lookback window in months (leave blank to disable)
        required: false
        default: ""
      SINCE:
        description: ISO date (YYYY-MM-DD) to start from (overrides MONTHS)
        required: false
        default: ""

      # Cloud checkboxes (default)
      CLOUD_GENERAL:
        type: boolean
        required: false
        default: true
        description: Include General (Worldwide)
      CLOUD_GCC:
        type: boolean
        required: false
        default: false
        description: Include GCC
      CLOUD_GCCH:
        type: boolean
        required: false
        default: false
        description: Include GCC High
      CLOUD_DOD:
        type: boolean
        required: false
        default: false
        description: Include DoD

      # Fallback (commented) — single textbox:
      # CLOUDS:
      #   description: Comma-separated clouds (e.g. General,GCC High,DoD)
      #   required: false
      #   default: General

      # Optional AI
      USE_OPENAI:
        type: boolean
        required: false
        default: false
        description: Use OpenAI to auto-fill narrative sections
      OPENAI_MODEL:
        required: false
        default: gpt-4o-mini
        description: OpenAI model when using AI
      PROMPT_PATH:
        required: false
        default: prompts/feature_summarize_tailored.md
        description: Prompt file for AI summarization

jobs:
  build:
    runs-on: ubuntu-latest
    env:
      TITLE: ${{ github.event.inputs.TITLE }}
      PUBLIC_IDS: ${{ github.event.inputs.PUBLIC_IDS }}
      MONTHS: ${{ github.event.inputs.MONTHS }}
      SINCE: ${{ github.event.inputs.SINCE }}

      CLOUD_GENERAL: ${{ github.event.inputs.CLOUD_GENERAL }}
      CLOUD_GCC: ${{ github.event.inputs.CLOUD_GCC }}
      CLOUD_GCCH: ${{ github.event.inputs.CLOUD_GCCH }}
      CLOUD_DOD: ${{ github.event.inputs.CLOUD_DOD }}

      # CLOUDS: ${{ github.event.inputs.CLOUDS }}  # (fallback only)

      USE_OPENAI: ${{ github.event.inputs.USE_OPENAI }}
      OPENAI_MODEL: ${{ github.event.inputs.OPENAI_MODEL }}
      PROMPT_PATH: ${{ github.event.inputs.PROMPT_PATH }}

      # Secrets → env
      TENANT: ${{ secrets.GRAPH_TENANT_ID }}
      CLIENT: ${{ secrets.GRAPH_CLIENT_ID }}
      PFX_B64: ${{ secrets.M365_PFX_BASE64 }}
      PFX_PASSWORD_ENV: M365_PFX_PASSWORD
      M365_PFX_PASSWORD: ${{ secrets.M365_PFX_PASSWORD }}   # <-- ensure value present
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      OPENAI_ORG_ID: ${{ secrets.OPENAI_ORG_ID }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          if [[ -f requirements.txt ]]; then
            pip install -r requirements.txt
          else
            pip install requests beautifulsoup4 lxml feedparser python-dateutil pandas openai msal cryptography
          fi

      - name: Prepare Graph config
        id: graphcfg
        shell: bash
        run: |
          set -euo pipefail
          CFG_PATH="graph_config.json"
          PFX="${PFX_B64:-}"
          if [[ -z "${PFX}" && -f "${CFG_PATH}" ]]; then
            echo "Reading pfx_base64 from ${CFG_PATH}"
            PFX="$(python -c 'import json,sys;print(json.load(open(sys.argv[1],\"r\",encoding=\"utf-8\")).get(\"pfx_base64\",\"\"))' "${CFG_PATH}")"
          fi
          if [[ -n "${TENANT:-}" && -n "${CLIENT:-}" && -n "${PFX:-}" ]]; then
            python - <<'PY'
              import os, json
              cfg={"tenant_id":os.environ.get("TENANT",""),
                  "client_id":os.environ.get("CLIENT",""),
                  "pfx_base64":os.environ.get("PFX_B64",""),
                  "pfx_password_env":os.environ.get("PFX_PASSWORD_ENV","M365_PFX_PASSWORD"),
                  "graph_base":"https://graph.microsoft.com/v1.0",
                  "authority_base":"https://login.microsoftonline.com"}
              open("graph_config.json","w",encoding="utf-8").write(json.dumps(cfg, ensure_ascii=False))
              print("graph_config.json written.")
            PY
            echo "graph_cfg=graph_config.json" >> "$GITHUB_OUTPUT"
          elif [[ -f "${CFG_PATH}" ]]; then
            echo "Existing ${CFG_PATH} will be used."
            echo "graph_cfg=${CFG_PATH}" >> "$GITHUB_OUTPUT"
          else
            echo "graph_cfg=" >> "$GITHUB_OUTPUT"
            echo "No Graph config available; will proceed if --no-graph is used."
          fi

      - name: Build cloud args (booleans)
        id: clouds
        shell: bash
        run: |
          set -euo pipefail
          args=()
          low() { echo "${1:-}" | tr '[:upper:]' '[:lower:]'; }
          if [[ "$(low "${{ github.event.inputs.CLOUD_GENERAL }}")" == "true" ]]; then args+=( --cloud "Worldwide (Standard Multi-Tenant)" ); fi
          if [[ "$(low "${{ github.event.inputs.CLOUD_GCC }}")" == "true" ]]; then args+=( --cloud "GCC" ); fi
          if [[ "$(low "${{ github.event.inputs.CLOUD_GCCH }}")" == "true" ]]; then args+=( --cloud "GCC High" ); fi
          if [[ "$(low "${{ github.event.inputs.CLOUD_DOD }}")" == "true" ]]; then args+=( --cloud "DoD" ); fi
          printf 'clouds=%q' "${args[*]}" >> "$GITHUB_OUTPUT"

      - name: Fetch master data (Graph/Public/RSS)
        id: fetch
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p output
          CSV_OUT="output/${TITLE}_master.csv"
          JSON_OUT="output/${TITLE}_master.json"
          STATS_OUT="output/${TITLE}_fetch_stats.json"

          DATE_FLAGS=()
          if [[ -n "${SINCE}" ]]; then
            DATE_FLAGS+=( --since "${SINCE}" )
          elif [[ -n "${MONTHS}" ]]; then
            DATE_FLAGS+=( --months "${MONTHS}" )
          fi

          CLOUDS_ARR=()
          # shellcheck disable=SC2206
          CLOUDS_ARR=(${{ steps.clouds.outputs.clouds }})

          CFG_ARG=()
          if [[ -n "${{ steps.graphcfg.outputs.graph_cfg }}" ]]; then
            CFG_ARG=( --config "${{ steps.graphcfg.outputs.graph_cfg }}" )
          fi

          python scripts/fetch_messages_graph.py \
            "${CFG_ARG[@]}" \
            "${DATE_FLAGS[@]}" \
            "${CLOUDS_ARR[@]}" \
            --ids "${PUBLIC_IDS}" \
            --emit csv --out "${CSV_OUT}" \
            --stats-out "${STATS_OUT}"

          python scripts/fetch_messages_graph.py \
            "${CFG_ARG[@]}" \
            "${DATE_FLAGS[@]}" \
            "${CLOUDS_ARR[@]}" \
            --ids "${PUBLIC_IDS}" \
            --emit json --out "${JSON_OUT}"

          echo "csv=${CSV_OUT}"     >> "$GITHUB_OUTPUT"
          echo "json=${JSON_OUT}"   >> "$GITHUB_OUTPUT"
          echo "stats=${STATS_OUT}" >> "$GITHUB_OUTPUT"

      - name: Dump fetch stats (debug)
        if: always()
        run: |
          test -f "${{ steps.fetch.outputs.stats }}" && cat "${{ steps.fetch.outputs.stats }}" || echo "no stats file"

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ${{ github.event.inputs.TITLE }}
          if-no-files-found: warn
          path: |
            output/${{ github.event.inputs.TITLE }}_master.csv
            output/${{ github.event.inputs.TITLE }}_master.json
            output/${{ github.event.inputs.TITLE }}_fetch_stats.json
            output/*
