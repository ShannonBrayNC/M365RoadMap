name: Build Microsoft 365 Roadmap Report

on:
  workflow_dispatch:
    inputs:
      title:
        description: "Report title (used in filenames)"
        required: true
        default: "roadmap_report"
      use_graph:
        description: "Use Graph Message Center (needs graph_config.json + cert)"
        required: true
        type: boolean
        default: false
      public_ids:
        description: "Comma-separated Roadmap IDs for public fallback (e.g., 498159,499430)"
        required: false
        default: ""
      months:
        description: "Months back (1..6) for Graph (ignored if 'since' is set)"
        required: false
        default: "3"
      since:
        description: "Since date (YYYY-MM-DD) for Graph (overrides 'months' if set)"
        required: false
        default: ""
      until:
        description: "Until date (kept for compatibility; not used by Graph)"
        required: false
        default: ""
      tenant_cloud:
        description: "Cloud instance label for Graph rows (e.g., Worldwide, GCC, GCC High, DoD)"
        required: false
        default: "Worldwide (Standard Multi-Tenant)"
      skip_generate:
        description: "Skip markdown generation (fetch only)"
        required: true
        type: boolean
        default: false

env:
  PYTHONUNBUFFERED: "1"

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Python deps (requirements.txt)
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install Playwright browsers (only if playwright in requirements.txt)
        if: ${{ inputs.public_ids != '' || inputs.use_graph == false }}
        run: |
          if grep -q 'playwright' requirements.txt; then
            echo "playwright found in requirements.txt — installing browsers..."
            python -m playwright install --with-deps chromium
          else
            echo "playwright not listed in requirements.txt — skipping browser install."
          fi


      - name: Ensure scripts are executable (if present)
        run: |
          chmod +x scripts/generate_report.sh || true
          chmod +x scripts/post_process.sh || true

      - name: Ensure output dir
        run: mkdir -p output

      - name: Show Graph config presence
        run: |
          if [ -f graph_config.json ]; then
            echo "graph_config.json found."
          else
            echo "graph_config.json NOT found (Graph fetch will fail if use_graph=true)."
          fi


      # Add this BEFORE "Fetch rows (Graph primary, public fallback)"
      - name: Discover IDs via RSS when none provided
        id: discover_rss
        if: ${{ inputs.public_ids == '' }}
        shell: bash
        run: |
          set -euo pipefail
          python - <<'PY' > output/rss_ids.txt
          import json, sys, requests, os
          months = os.getenv("MONTHS", "")   # passed from inputs env later in job
          since  = os.getenv("SINCE", "")
          # Pull the official JSON surface behind RSS
          data = requests.get("https://www.microsoft.com/releasecommunications/api/v2/m365/rss", timeout=60).json()
          items = None
          for k in ("value","items","Items","results","Results","data","Data"):
              if isinstance(data.get(k), list):
                  items = data[k]; break
          if items is None and isinstance(data, list):
              items = data
          from datetime import datetime, timedelta
          cut = None
          if months:
              try:
                  m = int(months)
                  cut = datetime.utcnow() - timedelta(days=int(30.44*m))
              except: pass
          if since and not cut:
              try:
                  sdt = datetime.strptime(since, "%Y-%m-%d")
                  cut = sdt
              except: pass
          def fid(it):
              for k in ("featureId","FeatureId","id","ID","Id"):
                  if k in it and it[k]:
                      return str(it[k]).strip()
              return ""
          def lastmod(it):
              for k in ("modified","lastModified","LastModified","lastModifiedDateTime"):
                  if k in it and it[k]:
                      try:
                          return datetime.fromisoformat(str(it[k]).replace("Z","+00:00"))
                      except: pass
              return None
          ids = []
          for it in (items or []):
              f = fid(it)
              if not f: continue
              if cut:
                  lm = lastmod(it)
                  if lm and lm < cut:
                      continue
              ids.append(f)
          print(",".join(sorted(set(ids))[:150]))  # cap for safety
          PY
              DISCOVERED=$(cat output/rss_ids.txt | tr -d '\n\r')
              echo "public_ids=${DISCOVERED}" >> "$GITHUB_OUTPUT"


      - name: Write PFX from secret (Linux)
        if: ${{ inputs.use_graph == true }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p .secrets
          echo "${M365_PFX_B64}" | base64 -d > .secrets/m365cert.pfx
          # small sanity check
          test -s .secrets/m365cert.pfx || (echo "PFX write failed" && exit 1)
        env:
          M365_PFX_B64: ${{ secrets.M365_PFX_B64 }}

      - name: Export PFX password to env
        if: ${{ inputs.use_graph == true }}
        shell: bash
        run: echo "M365_PFX_PASSWORD=${M365_PFX_PASSWORD}" >> $GITHUB_ENV
        env:
          M365_PFX_PASSWORD: ${{ secrets.M365_PFX_PASSWORD }}





      # Fetch rows -> master CSV/JSON using Graph + public (Playwright) + RSS/JSON fallbacks
      - name: Fetch rows (Graph primary, public + RSS fallbacks)
        id: fetch_rows
        shell: bash
        env:
          TITLE: ${{ inputs.title }}
          USE_GRAPH: ${{ inputs.use_graph }}
          PUBLIC_IDS: ${{ inputs.public_ids != '' && inputs.public_ids || steps.discover_rss.outputs.public_ids }}
          MONTHS: ${{ inputs.months }}
          SINCE: ${{ inputs.since }}
          TENANT_CLOUD: ${{ inputs.tenant_cloud }}

        run: |
          set -euo pipefail

          CSV_OUT="output/${TITLE}_master.csv"
          JSON_OUT="output/${TITLE}_master.json"
          STATS_OUT="output/${TITLE}_fetch_stats.json"

          # Flags
          if [[ "${USE_GRAPH}" == "true" ]]; then
            GRAPH_FLAG=""
          else
            GRAPH_FLAG="--no-graph"
          fi

          IDS_FLAG=""
          if [[ -n "${PUBLIC_IDS}" ]]; then
            IDS_FLAG="--ids ${PUBLIC_IDS}"
          fi

          DATE_FLAGS=""
          if [[ -n "${SINCE}" ]]; then
            DATE_FLAGS="--since ${SINCE}"
          elif [[ -n "${MONTHS}" ]]; then
            DATE_FLAGS="--months ${MONTHS}"
          fi

          echo "Running fetch_messages_graph.py ${GRAPH_FLAG} ${IDS_FLAG} ${DATE_FLAGS}"
          python scripts/fetch_messages_graph.py \
            --config graph_config.json \
            ${GRAPH_FLAG} ${IDS_FLAG} ${DATE_FLAGS} \
            --tenant-cloud "${TENANT_CLOUD}" \
            --emit csv --out "${CSV_OUT}" \
            --stats-out "${STATS_OUT}" --debug

          python scripts/fetch_messages_graph.py \
            --config graph_config.json \
            ${GRAPH_FLAG} ${IDS_FLAG} ${DATE_FLAGS} \
            --tenant-cloud "${TENANT_CLOUD}" \
            --emit json --out "${JSON_OUT}" --debug

          echo "csv=${CSV_OUT}"   >> "$GITHUB_OUTPUT"
          echo "json=${JSON_OUT}" >> "$GITHUB_OUTPUT"
          echo "stats=${STATS_OUT}" >> "$GITHUB_OUTPUT"

      - name: One-line method summary
        if: ${{ success() }}
        id: method_summary
        shell: bash
        env:
          STATS_PATH: ${{ steps.fetch_rows.outputs.stats }}
        run: |
          set -euo pipefail
          if [[ -f "${STATS_PATH}" ]]; then
            LINE=$(python - <<'PY'
          import json, os
          p=os.environ["STATS_PATH"]
          with open(p, encoding="utf-8") as f:
              s=json.load(f)
          print(f"[rows] Graph={s.get('graph',0)} Public={s.get('public',0)} RSS={s.get('rss',0)} Total={s.get('total',0)}")
          PY
          )
                      echo "${LINE}"
                      echo "${LINE}" >> "$GITHUB_STEP_SUMMARY"
                      echo "summary_line=${LINE}" >> "$GITHUB_OUTPUT"
                    else
                      echo "No stats file found at ${STATS_PATH}"
                    fi

      # Extract Roadmap IDs from the master CSV (if any official roadmap links are present)
      - name: Derive Roadmap IDs from CSV
        id: ids_from_csv
        if: ${{ success() }}
        shell: bash
        env:
          CSV_PATH: ${{ steps.fetch_rows.outputs.csv }}
        run: |
          set -euo pipefail
          IDS=""
          if [[ -f "${CSV_PATH}" ]]; then
            IDS=$(awk -F, 'NR>1 {print $NF}' "${CSV_PATH}" | \
              grep -oE 'featureid=[0-9]+' | grep -oE '[0-9]+' | sort -u | paste -sd, - || true)
          fi
          echo "Derived IDs: ${IDS}"
          echo "ids=${IDS}" >> "$GITHUB_OUTPUT"

      # Generate Markdown only if not skipped AND we have IDs (derived or user-provided)
      - name: Generate Markdown (Deep Dive)
        if: ${{ inputs.skip_generate == false && (steps.ids_from_csv.outputs.ids != '' || inputs.public_ids != '') }}
        shell: bash
        env:
          TITLE: ${{ inputs.title }}
          USER_IDS: ${{ inputs.public_ids }}
          DERIVED_IDS: ${{ steps.ids_from_csv.outputs.ids }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_ORG_ID: ${{ secrets.OPENAI_ORG_ID }}
        run: |
          set -euo pipefail
          IDS="${DERIVED_IDS}"
          if [[ -z "${IDS}" && -n "${USER_IDS}" ]]; then
            IDS="${USER_IDS}"
          fi

          echo "Using IDs for Deep Dive: ${IDS}"

          if [[ -z "${OPENAI_API_KEY:-}" ]]; then
            echo "OPENAI_API_KEY not set; skipping generation." >&2
            exit 0
          fi

          bash scripts/generate_report.sh "${IDS}" "prompts/system_multi_id.md" "output/${TITLE}.md"

      - name: Post-process (MD -> CSV/JSON)
        if: ${{ inputs.skip_generate == false }}
        shell: bash
        env:
          TITLE: ${{ inputs.title }}
          MONTHS: ${{ inputs.months }}
          SINCE: ${{ inputs.since }}
          UNTIL: ${{ inputs.until }}
          INCLUDE: ""
          EXCLUDE: ""
        run: |
          set -euo pipefail
          MD="output/${TITLE}.md"
          if [[ -f "${MD}" ]]; then
            echo "Converting ${MD} -> CSV/JSON"
            bash scripts/post_process.sh \
              "output/${TITLE}.md" \
              "output/${TITLE}_from_md.csv" \
              "output/${TITLE}_from_md.json" \
              "${MONTHS}" "${SINCE}" "${UNTIL}" "${INCLUDE}" "${EXCLUDE}"
          else
            echo "No markdown produced; skipping post-process."
          fi

      - name: Upload artifacts (unique name)
        uses: actions/upload-artifact@v4
        with:
          name: roadmap-report-${{ github.run_id }}
          if-no-files-found: warn
          path: |
            output/*.md
            output/*.csv
            output/*.json
